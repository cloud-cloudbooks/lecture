{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>word2vec with naver movie comments</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RYU\\Anaconda3\\envs\\tensor\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('ratings_train.txt', delimiter='\\t')\n",
    "test = pd.read_csv('ratings_test.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segs = np.load('train_segs.npy')\n",
    "train_sents = np.load('train_sents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['아', '더빙', '..', '진짜', '짜증', '나네', '요', '목소리']),\n",
       "       list(['흠', '...', '포스터', '보고', '초딩', '영화', '줄', '....', '오버', '연기', '조차', '가볍', '지', '않구', '나']),\n",
       "       list(['너무', '재', '밓었', '다', '그래서', '보는', '것', '을', '추천한', '다']),\n",
       "       ...,\n",
       "       list(['이', '게', '뭐', '요', '?', '한국인', '은', '거들', '먹거리', '고', '필리핀', '혼혈', '은', '착하다', '?']),\n",
       "       list(['청춘', '영화', '의', '최고봉', '.', '방황', '과', '우울했', '던', '날', '들', '의', '자화상']),\n",
       "       list(['한국', '영화', '최초', '로', '수간', '하는', '내용', '이', '담긴', '영화'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(min_count=2, window=5, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9981392, 12261135)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_segs, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34371"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('고바야시', 0.8150112628936768),\n",
       " ('허네', 0.7881859540939331),\n",
       " ('용자', 0.7832287549972534),\n",
       " ('김지영', 0.7814315557479858),\n",
       " ('섹시하다', 0.7814275622367859),\n",
       " ('슥', 0.7807300686836243),\n",
       " ('강츄', 0.7806259989738464),\n",
       " ('미셀', 0.7792251110076904),\n",
       " ('하마', 0.7782269716262817),\n",
       " ('..~~', 0.7758156061172485)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=['광해', '황정민'], negative=['이병헌'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(ngram_range=(1,1), min_df=2).fit(train_sents.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31455\n"
     ]
    }
   ],
   "source": [
    "print(len(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.inverse_vocabulary_ = {vect.vocabulary_[k] : k for k in vect.vocabulary_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.vocabulary_.keys()\n",
    "#{'더빙': 16437,\n",
    "#'진짜': 59534,\n",
    "#'짜증나네요': 59954,\n",
    "#'목소리': 23329,\n",
    "#'포스터보고': 65489, ...}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensor",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
