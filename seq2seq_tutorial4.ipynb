{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = []\n",
    "korean = []\n",
    "count = 100\n",
    "with open('korean-english-park.train.en', 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        english.append(line)\n",
    "        if i-1 == count:\n",
    "            break\n",
    "\n",
    "with open('korean-english-park.train.ko', 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        korean.append(line)\n",
    "        if i-1 == count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(english)):\n",
    "    english[i] = re.sub('\\n', '', english[i])\n",
    "for i in range(len(korean)):\n",
    "    korean[i] = re.sub('\\n', '', korean[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(english)):\n",
    "    english[i] = english[i].split()\n",
    "for i in range(len(korean)):\n",
    "    korean[i] = korean[i].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = np.stack((english, korean), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_arr = []\n",
    "for seq in english:\n",
    "    word_arr += seq\n",
    "word_arr += ['<P>']\n",
    "en_word2num = {c:i for i, c in enumerate(set(word_arr))}\n",
    "en_num2word = {i:c for i, c in enumerate(en_word2num.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_arr = []\n",
    "for seq in korean:\n",
    "    word_arr += seq\n",
    "word_arr += ['<S>', '</S>', '<P>']\n",
    "ko_word2num = {c:i for i, c in enumerate(set(word_arr))}\n",
    "ko_num2word = {i:c for i, c in enumerate(ko_word2num.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(seq_data):\n",
    "    max_len = 0\n",
    "    for seq in seq_data:\n",
    "        if max_len < len(seq):\n",
    "            max_len = len(seq)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data, enc_max_len, dec_max_len):\n",
    "    input_batch = []\n",
    "    output_batch = []\n",
    "    target_batch = []\n",
    "    for i, seq in enumerate(seq_data):\n",
    "        input = []\n",
    "        output = []\n",
    "        target = []\n",
    "        for token in seq[0]:\n",
    "            input.append(en_word2num[token])\n",
    "        for _ in range(len(seq[0]), enc_max_len):\n",
    "            input.append(en_word2num['<P>'])\n",
    "        input_batch.append(input)\n",
    "        output.append(ko_word2num['<S>'])\n",
    "        for token in seq[1]:\n",
    "            output.append(ko_word2num[token])\n",
    "            target.append(ko_word2num[token])\n",
    "        target.append(ko_word2num['</S>'])\n",
    "        for _ in range(len(seq[1]), dec_max_len):\n",
    "            output.append(ko_word2num['</S>'])\n",
    "            target.append(ko_word2num['</S>'])\n",
    "                \n",
    "        output_batch.append(output)\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_length(seq_data):\n",
    "    seq_len = []\n",
    "    for i, seq in enumerate(seq_data):\n",
    "        seq_len.append(len(seq))\n",
    "    return seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "n_hidden = 256\n",
    "max_enc_step = get_max_length(english)\n",
    "max_dec_step = get_max_length(korean)\n",
    "n_embedding = 300\n",
    "total_epoch = 300\n",
    "n_input = en_dic_len\n",
    "n_class = ko_dic_len\n",
    "batch_size = count\n",
    "en_dic_len = len(en_word2num)\n",
    "ko_dic_len = len(ko_word2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "enc_input = tf.placeholder(tf.int32, [None, max_enc_step])\n",
    "dec_input = tf.placeholder(tf.int32, [None, max_dec_step+1])\n",
    "dec_inputs = tf.one_hot(dec_input, ko_dic_len)\n",
    "W = tf.get_variable(name='embedding', shape=[en_dic_len, n_embedding], trainable=True)\n",
    "targets = tf.placeholder(tf.int64, [None, None])\n",
    "enc_seq_len = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "dec_seq_len = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "enc_inputs = tf.nn.embedding_lookup(W, enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "    #enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_inputs, sequence_length=enc_seq_len, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "    #dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(dec_cell, dec_inputs, initial_state = enc_states, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(outputs, n_class, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.contrib.seq2seq.sequence_loss(logits=logits, targets=targets, weights=tf.sequence_mask(dec_seq_len+1, max_dec_step+1, dtype=tf.float32)))\n",
    "predict = tf.argmax(logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 050 cost = 0.109170\n",
      "epoch: 100 cost = 0.069113\n",
      "epoch: 150 cost = 0.028720\n",
      "epoch: 200 cost = 0.013574\n",
      "epoch: 250 cost = 0.007768\n",
      "epoch: 300 cost = 0.004848\n",
      "optimization finished!\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_batch = int(len(seq_data)/batch_size)\n",
    "for epoch in range(total_epoch):\n",
    "    loss_sum = 0\n",
    "    #print('< epoch:', epoch+1, '>')\n",
    "    for i in range(total_batch):\n",
    "        if i == (total_batch-1):\n",
    "            input_batch, output_batch, target_batch = make_batch(seq_data[i*batch_size:len(seq_data)], max_enc_step, max_dec_step)\n",
    "            enc_seq_data = get_seq_length(english[i*batch_size:len(seq_data)])\n",
    "            dec_seq_data = get_seq_length(korean[i*batch_size:len(seq_data)])\n",
    "        else:\n",
    "            input_batch, output_batch, target_batch = make_batch(seq_data[i*batch_size:(i+1)*batch_size], max_enc_step, max_dec_step)\n",
    "            enc_seq_data = get_seq_length(english[i*batch_size:(i+1)*batch_size])\n",
    "            dec_seq_data = get_seq_length(korean[i*batch_size:(i+1)*batch_size])\n",
    "        \n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={enc_input: input_batch, dec_input: output_batch, targets: target_batch, enc_seq_len: enc_seq_data, dec_seq_len: dec_seq_data})\n",
    "        loss_sum += loss\n",
    "        #if i % 30 == 29:\n",
    "        #    print('batch:', '%03d' % (i+1), 'cost =', '{:.6f}'.format(loss_sum/30))\n",
    "        #    loss_sum = 0\n",
    "    if epoch % 50 == 49:\n",
    "        print('epoch:', '%03d' % (epoch+1), 'cost =', '{:.6f}'.format(loss_sum/50))\n",
    "        \n",
    "print('optimization finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(english):\n",
    "    english = [english]\n",
    "    korean = [['<P>']*max_dec_step]\n",
    "    seq_data = [english + korean]\n",
    "    input_batch, output_batch, target_batch = make_batch(seq_data, max_enc_step, max_dec_step)\n",
    "    enc_seq_data = get_seq_length(english)\n",
    "    dec_seq_data = get_seq_length(korean)\n",
    "    result = sess.run(predict, feed_dict={enc_input: input_batch, dec_input: output_batch, targets: target_batch, enc_seq_len: enc_seq_data, dec_seq_len: dec_seq_data})\n",
    "    decoded = [ko_num2word[j] for j in np.squeeze(result)]\n",
    "    end = len(decoded)-1\n",
    "    if '</S>' in decoded:\n",
    "        end = decoded.index('</S>')\n",
    "    translated = ' '.join(decoded[:end])\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Much of personal computing is about \"can you top this?\"  \n",
      "-> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 있느냐?\" 있느냐?\" \n",
      "\n",
      "so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.  \n",
      "-> 모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다. \n",
      "\n",
      "Like all optical mice, But it also doesn't need a desk.  \n",
      "-> 그러나 이것은 또한 책상도 필요로 하지 않는다. \n",
      "\n",
      "uses gyroscopic sensors to control the cursor movement as you move your wrist, arm, whatever through the air.  \n",
      "-> 79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분이든 움직임에따라 움직임에따라 커서의 움직임을 조절하는 회전 운동 있다. 있다. \n",
      "\n",
      "Intelligence officials have revealed a spate of foiled plots on ships in Southeast Asia and are warning that a narrow stretch of water carrying almost one third of the world's maritime trade is vulnerable to a terror attack.  \n",
      "-> 정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔음을 밝혔으며, 해상 해상 교역량의 거의 3분의 1을 운송하는 좁은 해로인 말라카 해협이 공격을 당하기 쉽다고 경고하고 경고하고 \n",
      "\n",
      "After learning of several foiled al Qaeda attempts on U.S. and commercial ships in the area, experts are warning that the terror network still wants to cripple the global economy, the world's economic jugular vein in Southeast Asia is at risk.  \n",
      "-> 이 지역에 있는 미국 선박과 상업용 선박들에 대한 알카에다의 (테러) 시도 중 여러 건이 실패했다는 것을 알게 알게 된 전문가들은 테러 테러 조직이 여전히 경제에 타격을 입히려 입히려 경고하고 동남 동남 아시아에 세계 있는 통로가 위험에 생각하고 생각하고 있다. \n",
      "\n",
      "Caffeine can help increase reaction time and improve performance for military servicemen who must perform complex tasks or who need help staying alert for longer periods of time, according to a new report by the National Academy of Sciences.  \n",
      "-> 국립 과학 학회가 발표한 새 보고서에따르면, 복잡한 임무를 수행해야 하는 군인들이나 보다 오랜 시간 시간 경계를 늦추지 않고 있기 위해 필요한 필요한 카페인이 카페인이 시간을 임무 임무 수행 수행 향상시키는데 도움이 \n",
      "\n",
      "\"Specifically, it can be used in maintaining speed of reactions and visual and auditory vigilance, which in military operations could be a life or death situation,\" according to the report.  \n",
      "-> 이 보고서에따르면, \"특히, 군사 작전에서 생사가 걸린 상황이 될 수도 있는 속도와 속도와 시각 청각의 청각의 경계 상태를 유지시키기 카페인이 카페인이 카페인이 있다.\" 고 한다. \n",
      "\n",
      "\"Something that will boost their capabilities at crucial moments is very important.\"  \n",
      "-> \"결정적인 순간에 그들의 능력을 증가시켜 줄 그 무엇이 매우 중요합니다.\" \n",
      "\n",
      "Researchers are already exploring ways to put caffeine in nutrition bars or chewing gum as alternatives to coffee, Archibald said.  \n",
      "-> 연구가들이 이미 커피 대체품으로서 음식 대용 과자나 껌에 카페인을 첨가하는 방법을 연구하고 Archibald는 Archibald는 Archibald는 \n",
      "\n",
      "A similar dose of caffeine, about 200-600 mg, also appears effective in enhancing physical endurance and may be especially useful in returning some of the physical endurance lost at high altitude, the study found.  \n",
      "-> 약 200600밀리그램의, 비슷한 분량의 카페인은 또한 육체적 지구력을 강화시키는 강화시키는 효과적인 것 같으며, 고도가 고도가 곳에서 곳에서 약해진 육체적 지구력을 회복시켜주는 회복시켜주는 유용하다는 유용하다는 고 고 한다. \n",
      "\n",
      "The Institute of Medicine is part of the National Academy of Sciences, a private organization chartered by Congress to advise the government on scientific matters.  \n",
      "-> 의약 연구소는 정부에 과학 문제에 관해 자문하기 위해 의회가 설립 인가를 내어 준 민간 단체인 국립 과학 학회의 부속 단체이다. \n",
      "\n",
      "thanks to robust demand in Asia, boosting the trade surplus to 1.055 trillion yen ($8.47 billion), the Ministry of Finance said.  \n",
      "-> 아시아에서의 왕성한 수요 덕분에 일본의 수출이 9월에 연속 6개월간 증가하여, 무역 흑자가 1조550억엔(84억7,000만달러)으로 늘어났다고 재무성이 \n",
      "\n",
      "But the prospect of a slowing U.S. economy and weak demand at home overshadowed any optimism for the months ahead.  \n",
      "-> 그러나 침체되고 있는 미국 경제와 국내 수요의 약세 전망이 향후 수개월 동안의 낙관론을 어둡게 했다. \n",
      "\n",
      "More than 750 hostages were rescued, including all 75 non-Russians and 25 children, when special forces stormed the building.  \n",
      "-> 특수 부대가 극장 건물로 공격해 들어가면서, 러시아인이 아닌 75명의 외국인과 25명의 어린이 전부를 포함해 750명 \n",
      "\n",
      "Russian special forces used a sedative gas before storming the theatre.  \n",
      "-> 러시아 특수 부대는 극장으로 공격해 들어가기 들어가기 신경 독가스를 사용했다. 사용했다. \n",
      "\n",
      "Many captives were taken to hospital suffering from the effects of the chemical.  \n",
      "-> 많은 인질들이 화학 가스의 영향으로 고통을 겪으며 병원으로 옮겨졌다. \n",
      "\n",
      "marking a historic shift to the left for Latin America's largest country.  \n",
      "-> 과거 노조 지도자였던 루이스 이나시오 룰라 다 실바가 브라질의 대통령 선거 결선 투표에서 거두면서, 라틴 라틴 \n",
      "\n",
      "hours after Silva's Workers Party had declared their candidate the winner.  \n",
      "-> 실바의 노동자당이 자신들의 자신들의 이후에 이후에 선거의 선거의 승리자라고 선언한 몇 시간이 시간이 지나, 집권당 후보인 후보인 후보인 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 세하는 \n",
      "\n",
      "Thousands of Silva supporters gathered in the streets of Sao Paulo and Rio de Janeiro, waving his party's red flag in celebration.  \n",
      "-> 수천명의 실바 지지자들이 상 파울로와 리오 데 자네이로의 거리에 모여 들어, 실바가 이끄는 당의 붉은 깃발을 흔들며 \n",
      "\n",
      "Amid mounting pressure on North Korea to abandon its nuclear weapons program Japanese and North Korean diplomats have resumed talks on normalizing diplomatic relations.  \n",
      "-> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다. 재개했다. \n",
      "\n",
      "The two days of meetings in the Malaysian capital, Kuala Lumpur, are expected to be dominated by Japanese concerns over the North's bomb-making efforts, as well as calls for a fuller explanation over the kidnapping of Japanese civilians in the 1970s and 80s.  \n",
      "-> 말레이시아의 수도 쿠알라 룸푸르에서 열리는 이틀간의 회담에서는 1970년대와 80년대에 있었던 일본 민간인들의 납치에 대한 충분한 충분한 설명을 요청하는 뿐만아니라 뿐만아니라 (핵)폭탄 제조 제조 노력에 일본의 우려가 주로 \n",
      "\n",
      "At least 54 people have been confirmed dead but that figure is expected to rise, possibly to over 100  \n",
      "-> 100여명의 사망자가 예상되는 베트남 빌딩 화재 \n",
      "\n",
      "after a fire tore through a six-storey building in Vietnam's Ho Chi Minh City that housed shops, a disco and several foreign companies.  \n",
      "-> 상점, 디스코텍, 그리고 여러 외국 회사들이 들어 있는 베트남 호지민市의 6층 건물을 휩쓸어버린 화재가 발생하여, 적어도 54명이 사망한 확인되었는데 확인되었는데 \n",
      "\n",
      "Initial reports indicated it may have been sparked by a short-circuit in the Blue Disco on the building's second floor.  \n",
      "-> 최초 보도에 의하면 그 화재는 건물 2층의 Blue Disco에서 누전에 의해 발화되었을 발화되었을 했다. 했다. \n",
      "\n",
      "prevented firefighters from entering the building for about four hours with firefighters taking more than five hours to extinguish the inferno.  \n",
      "-> 소방관들이 그 지옥 같은 화재를 진압하는데는 5 시간 이상이 걸렸는데, 강한 열과 수그러들지 않는 불길 때문에 소방관들은 4시간 4시간 건물에 건물에 \n",
      "\n",
      "Mobile bomb-fighting robots can already inspect suspicious cars, buildings or mail for explosives or hazardous materials, according to Jan Karlsson, an expert at the U.N.  \n",
      "-> 이동할 수 있는 폭탄 제거 로보트가 이미 폭발물이나 위험 물질이 있는 것으로 의심되는 자동차, 건물, 우편물을 우편물을 검사할 있다고, 있다고, 유엔의 경제 위원회 전문가인 Jan \n",
      "\n",
      "The Geneva-based commission, in its annual study of the industry titled “World Robotics 2001,” said a record 100,000 robots were installed last year, up 25 percent on 1999.  \n",
      "-> 어휘 : \n",
      "\n",
      "“There is definitely a much higher incentive to invest in automated technology to fight terrorists,” Karlsson said.  \n",
      "-> \"테러범들과 싸우기 위해서 자동화 기술에 투자하는 것이 분명히 훨씬 많은 이익이 있습니다,\" 라고 말했다. 말했다. \n",
      "\n",
      "“It could be used in post offices, in surveillance of offices after hours and to inspect suspicious cars.”  \n",
      "-> \"자동화 기술은 우체국에서, 그리고 업무가 끝난 후 사무실 경비에, 그리고 의심스러운 차량을 수색하는 수색하는 사용될 수 수 \n",
      "\n",
      "Postal Service - whose postmaster told a Senate panel that the financial impact of the anthrax crisis could be several billion dollars - uses robots to sort parcels, but other automated equipment sorts letters.  \n",
      "-> 어휘 : \n",
      "\n",
      "At the same time, labor costs are more and more.”  \n",
      "-> 그와 동시 에 노동 비용은 더욱 상승하고 있습니다.\" 말했다. 말했다. \n",
      "\n",
      "“For industrial robots, 2000 was the best year ever,” added the Swede.  \n",
      "-> \"산업용 로보트 분야에서 2000년은 최상의 해였습니다.\" 해였습니다.\" 라고 스웨덴인은 덧붙혀 \n",
      "\n",
      "“Not only in Japan and Europe and North America, but they have also started to take off in some developing countries, for example in Brazil, Mexico, China and South Africa.”  \n",
      "-> \"일본, 유럽 및 북아메리카 뿐만아니라 일부 개발도상국들, 예를들어 브라질, 중국 및 남아프리카에서도 산업용 로보트는 사용량이 폭증하기 시작했습니다. 시작했습니다. and 수도 \n",
      "\n",
      "Annual sales of robot units are estimated at $5 billion to $6 billion.  \n",
      "-> 로보트 장치의 연간 판매액은 50억60억달러로 추산되고 있다. \n",
      "\n",
      "But with the cost of installing necessary software and integration systems, the total robotics market could be worth closer to $25 billion.  \n",
      "-> 그러나 필수 소프트웨어 및 통합 시스템 설치 비용을 합할 경우, 전체 로보트 공학 시장의 가치는 250억달러에 달할 수 수 \n",
      "\n",
      "About 50 systems of firefighting and bomb-disposal robots have been sold through 2000 in countries including Israel and Britain.  \n",
      "-> 2000년까지 이스라엘과 영국을 비롯한 여러 국가들에서 화재 진압 및 폭탄 처리 로보트 시스템이 약 50대가 판매되었다. \n",
      "\n",
      "The study, written before the devastating U.S. attacks, predicts sales of 120 systems by 2004.  \n",
      "-> 미국에서 끔찍한 공격이 발생하기 전에 작성된 이 연구 보고서는 2004년까지 120대의 시스템이 판매될 \n",
      "\n",
      "About 2,300 robots work in demolition, servicing or dismantling nuclear, chemical, waste or other hazardous complexes, the report said.  \n",
      "-> 약 2,300대의 로보트가 핵, 화학 물질, 폐기물, 또는 기타 위험한 합성물을 파괴하거나, 처리하거나, 해체하는 작업을 하고 \n",
      "\n",
      "Another 60 robots work in surveillance.  \n",
      "-> 또 다른 60대의 로보트가 경비 일을 하고 \n",
      "\n",
      "“Guard robots are used privately and professionally to detect intruders or fire,” Karlsson said.  \n",
      "-> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 말했다. \n",
      "\n",
      "“The Pentagon have several, and they are used in nuclear plants in the United States and Europe, but the market is still rather marginal.\"  \n",
      "-> 라고 Karlsson이 말했다. \"국방성은 그러한 로보트를 여러 대 갖고 있으며, 그 로보트들은 미국과 유럽의 핵 발전소에서 사용되고 있지만, 시장은 아직도 한계를 벗어나지 못하고 \n",
      "\n",
      "Five United States Congressmen have written to President Bush urging him to punish North Korea for continuing with its nuclear weapons program and push for a change of government in the isolated Stalinist state.  \n",
      "-> 미국 의회 의원 5명은 북한이 핵무기 계획을 계속 진행하는 진행하는 대해 북한을 응징하고, 고립된 고립된 사회주의 국가에서의 정권 교체를 추진하라고 촉구하는 서한을 대통령에게 보냈다. \n",
      "\n",
      "In a letter to the administration, Republican Senators Jesse Helms, Bob Smith and John Kyl, Republican Representative Chris Cox and Democrat Representative Ed Markey called on the president for the U.S. to provide North Korea with fuel oil.  \n",
      "-> 행정부에 보낸 서한에서, 공화당 상원의원 제시 헬름스, 봅 스미스, 존 킬, 그리고 공화당 하원의원 크리스 콕스와 민주당 민주당 에드 마키는 대통령에게 대통령에게 북한에게 기름을 제공하기로 제공하기로 1994 1994 \n",
      "\n",
      "Four days of peace talks between the Sri Lankan government and Tamil rebels have ended on a high note as both sides bid to end one of Asia's longest-running conflicts.  \n",
      "-> 양측이 아시아에서 가장 오래 지속되어온 분쟁을 종식시키기 위해 노력함에따라, 스리랑카 정부와 타밀 반군 사이 의 4일간의 평화 회담이 큰 성과를 거두고 끝났다. \n",
      "\n",
      "Both sides declared success in Thailand, after they agreed to set up three committees to look at issues that lie at the heart of the 19-year-old war that has killed nearly 65,000 people and displaced more than 1.5 million.  \n",
      "-> 65,000명에 가까운 사상자를 냈으며, 150만명 이상을 피난시켰던 19년간의 전쟁에서의 핵심적인 쟁점들을 검토하기 3개 3개 위원회를 구성하기로 합의한 후에, 양측은 태국에서의 성공적이었다고 성공적이었다고 선언했다. \n",
      "\n",
      "The government says the new bodies will address ethnic and power-sharing issues and will also oversee a resettlement of refugees and restoration of areas destroyed by the decades-old civil war.  \n",
      "-> 새 기구들은 민족 문제와 권력 분할 문제를 중점적으로 다룰 것이며, 난민 재정착과 수십년간의 내전으로 파괴된 지역의 복구 문제를 감독할 정부는 말하고 \n",
      "\n",
      "A 194-vehicle pileup on a freeway south of Los Angeles left more than 40 people injured, five seriously, The accident occurred shortly before 7 a.m.  \n",
      "-> 로스앤젤레스 남부의 한 고속도로에서 194대의 차량이 연쇄 추돌하여 40명 이상이 부상당하고, 5명이 중상을 입었다고 경찰이 발표했다. 발표했다. \n",
      "\n",
      "and prompted the California Highway Patrol to close a two-mile stretch of Interstate 710 in both directions Traffic was being diverted to alternate routes.  \n",
      "-> 이 사고는 오전 7시 직전에 발생했으며, 사고가 나자 캘리포니아 고속도로 순찰대는 즉시 Interstate 710 도로의 2마일 구간을 양방향 모두 오후까지 폐쇄시켰다. \n",
      "\n",
      "Thick fog may have been a factor in the accident, California Highway Patrol officers said.  \n",
      "-> 짙은 안개가 사고의 요인이었을 것이라고 캘리포니아 고속도로 순찰대 관리들이 말했다. \n",
      "\n",
      "The best man raises his wine glass and out comes a drunken diatribe.  \n",
      "-> 신랑 들러리가 포도주 잔을 들어 올린다 그리고는 술주정을 늘어놓는다. \n",
      "\n",
      "It's a wedding couple's nightmare, but a growing number of love birds are shielding themselves by having Web sites ghostwrite the perfect toast.  \n",
      "-> 하지만 점점 더 많은 연인들이 웹사이트에 완벽한 축배의 말을 대신 써주도록 의뢰함으로써 실패로부터 실패로부터 자신들을 보호하고 \n",
      "\n",
      "For the right price, dozens of sites promise to find the right words for just about any occasion:  \n",
      "-> 적당한 가격의 돈을 받고, 수십개의 사이트들이 정치 집회, 세례식, 성인식, 장례식, 심지어 기업 광고 과 같은 같은 \n",
      "\n",
      "But toasts for the happy couple are the most frequent requests.  \n",
      "-> 그러나 행복한 신랑, 신부를 위한 축배의 말이 가장 빈번하게 의뢰되고 \n",
      "\n",
      "In a stunning and historical night for the GOP and President Bush, Republicans seized control of the Senate, held onto their majority in the House and savored wins in two hot gubernatorial races.  \n",
      "-> 美 공화당과 부시 대통령에게는 놀랍고도 역사적 밤 에, 공화당이 상원을 장악했으며, 하원에서도 과반수를 유지하였다. 유지하였다. 유지하였다. \n",
      "\n",
      "The Republicans will have at least a 51-seat majority Republicans won at least 226 seats, up from the 223 they had going into the election.  \n",
      "-> 하원 쪽에서는 공화당이 선거에 들어갈 때 차지하고 있던 223석에서 늘어나 늘어나 226석을 얻었다. 얻었다. 10위 \n",
      "\n",
      "China has unveiled plans for the largest water-diversion in its history and possibly one of the world's most expensive at $60.4 billion.  \n",
      "-> 중국이 604억달러의 비용이 소요되는 아마도 세계 에서 가장 값비싼 계획 중의 하나이며, 역사상 역사상 규모가 큰 큰 \n",
      "\n",
      "The project will channel water from the country's longest river, the Yangtze, to three rivers in the north, the Yellow, Huai and Hai, whose basins are running dry.  \n",
      "-> 이 사업은 중국에서 가장 긴 강인 양쯔강의 물을 강 유역이 말라 들어가고 북부의 북부의 황허, 화이허, 하이허, 세 개의 강으로 돌리게 될 것이다. \n",
      "\n",
      "The ambitious South-to-North Water Transfer Project will move water along three channels linking the wetter flood-prone southern basin to parched northern climes.  \n",
      "-> 이 야심찬 남북 수로 변경 사업은 더 습하고 홍수가 잦은 남부의 강 유역을 건조한 건조한 북부 지방과 연결시키는 세 개의 수로를 따라 이동시키게 것이다. \n",
      "\n",
      "This is just one of the latest of China's massive public works projects, recent ones including the Three Gorges hydroelectric dam, a proposed 4,000-kilometer natural-gas pipeline and the world's highest railroad from Qinghai to Tibet.  \n",
      "-> 최근의 사업 중에는 3개의 협곡 수력 발전 댐, 4,000킬로미터의 천연 가스 파이프라인 계획, 그리고 큉하이에서 티벳까지의 최고도의 최고도의 건설이 건설이 포함되어 포함되어 \n",
      "\n",
      "Authorities from the Water Resources Ministry plan to begin construction next year on the controversial and hugely expensive project.  \n",
      "-> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다. \n",
      "\n",
      "Vice Minister of the Water Resources ministry Zhang Jiyao said plans for the project would be submitted for approval to the cabinet by the end of the year.  \n",
      "-> 장쟈오 수자원부 차관은 사업 승인을 받기 위해 금년말까지 이 사업 계획이 의회에 제출될 것이라고 것이라고 말했다. 말했다. \n",
      "\n",
      "Environmental experts say the new project could cause widespread corruption, human hardship and environmental damage, and could dry up the Yangtze in 30 years.  \n",
      "-> 환경 전문가들은 이 새 사업이 광범위한 부패와 사람들의 고난, 그리고 환경 파괴를 야기시킬 수 30년내에 30년내에 양쯔강을 고갈시킬 수도 수도 \n",
      "\n",
      "They urge China to take simpler steps like raising water prices, curbing rampant well-digging, stopping up leaks and improving water treatment.  \n",
      "-> 그들은 중국이 물 가격 인상, 무분별한 우물 파기의 억제, 누수 방지, 그리고 용수 처리 방법의 개선과 같은 간단한 조치들을 취할 촉구하고 촉구하고 \n",
      "\n",
      "European officials have expressed concern the U.S. president will now be more emboldened, following his Republican party's mid-term election gains.  \n",
      "-> 유럽의 관리들은 공화당의 중간 선거 득표의 결과로 이제는 이제는 대통령이 특히 이라크에 이라크에 더욱 대담해질 것이라는 우려를 나타냈다. \n",
      "\n",
      "Europe and Bush have been at loggerheads over whether the threat of military action should be included in a new U.N. draft resolution on Iraq, and European leaders have also voiced concern about U.S. calls for \"regime change\" in Iraq.  \n",
      "-> 유럽과 부시는 이라크에 대한 새 유엔 결의안 초안에 군사 행동을 통한 위협을 포함시킬지 여부를 놓고 서로 다투어왔으며, 다투어왔으며, 지도자들은 지도자들은 이라크에서의 \"정권 교체\"를 바라는 미국의 주장에 주장에 우려를 우려를 \n",
      "\n",
      "The two sides have also had spats over a wide range of issues including global warming and the new International Criminal Court.  \n",
      "-> 양측은 또한 지구 온난화와 새 국제 형사 재판소를 포함한 광범위한 문제에 대해 견해 차이를 보여왔다. 보여왔다. \n",
      "\n",
      "\"Apocalypse Now,\" Francis Ford Coppola's anti-Vietnam War classic, is the greatest film of the past 25 years, according to a survey of British film critics and writers.  \n",
      "-> 영국의 영화 비평가와 작가들을 대상으로 한 조사에 의하면, 프란시스 포드 코폴라의 反베트남전 명작, \"지옥의 묵시록(Apocalypse Now)\"이 Now)\"이 25년 간 위대한 영화라고 영화라고 \n",
      "\n",
      "Two movies by Martin Scorsese also made the top 10 in the poll released by the British Film Institute's Sight & Sound magazine.  \n",
      "-> 마틴 스콜세지의 영화 두 편이 영국 영화 연구소의 Sight & Sound誌가 Sound誌가 여론 상위 상위 10위 안에 들었다. \n",
      "\n",
      "The 50 respondents chose Scorsese's \"Raging Bull\" as the second-best movie of the past quarter-century, followed by Ingmar Bergman's \"Fanny And Alexander\" in third place.  \n",
      "-> 50명의 응답자들은 스콜세지의 \"성난 황소(Raging Bull)\"를 지난 25년 간 두번째로 훌륭한 훌륭한 영화로 선정했으며, 잉그마르 베르그만의 \"패니와 알렉산더(Fanny and Alexander)\"가 3위로 뒤를 이었다. \n",
      "\n",
      "The Philippine Coast Guard and navy frogmen are searching for survivors in Manila Bay Two days after the crash, they had rescued 16 passengers and found 14 others who had died, navy officials said.  \n",
      "-> 34명을 태운 필리핀 국내 여객기가 추락한 후에 필리핀 해안 경비대와 해군 잠수부들이 마닐나 만(灣)에서 생존자를 수색하고 추락한지 이틀이 이틀이 지금 지금 까지 승객 16명을 구조했으며, 다른 다른 다른 해군 \n",
      "\n",
      "Four others are still missing.  \n",
      "-> 다른 4명은 아직도 실종된 상태이다. \n",
      "\n",
      "Survivors have been taken to hospitals around Manila Bay, a shore region off the Philippine capital of Manila.  \n",
      "-> 생존자들은 필리핀 수도 마닐라의 해안 지역인 마닐라 만(灣) 부근에 있는 병원들로 이송되었다. \n",
      "\n",
      "Emergency workers and stunned residents across the South and Great Lakes regions picked through shattered homes and buildings after a string of tornadoes left at least 36 people dead and dozens injured.  \n",
      "-> 잇따른 토네이도에 의해 36명의 사망자 발생 \n",
      "\n",
      "after more than 70 tornadoes touched down.  \n",
      "-> 70개 이상의 토네이도가 덮친 알라바마州에서 알라바마州에서 이르는 지역에서 가옥, 가옥, 학교, \n",
      "\n",
      "Most of those killed were in Tennessee, Following the Iraqi parliament's unanimous recommendation to reject the return of U.N. weapons inspectors, he is \"looking forward\" to receiving the country's final decision.  \n",
      "-> 유엔 무기 사찰관들의 복귀를 거부하라는 권고안을 이라크 의회가 만장일치로 채택한 후에, 코피 아난 사무총장은 사무총장은 이라크의 최종 결정을 받기를 \"기대하고 있다\"고 \n",
      "\n",
      "Iraq's ambassador to the United Nations, Mohammad Al-Douri, delivered a letter of acceptance to Kofi Annan, telling reporters that \"Iraq will not have any mass destruction weapons.  \n",
      "-> 하루가 지난 후 뉴욕에서, 이라크의 무하마드 알 두리 유엔 대사는 코피 아난에게 (사찰) 수용서를 전달했으며, 서한에는 서한에는 \"이라크는 대랑 살상 무기도 보유하지 않을 \n",
      "\n",
      "So we are not worried about the inspectors when they will be back in the country.  \n",
      "-> 따라서 우리는 (무기) 사찰단이 이라크로 다시 돌아온다 해도 그들에 그들에 불안해 하지 이라크는 이라크는 결백하다. \n",
      "\n",
      "especially if combined with weight-training, a Harvard study of more than 40,000 men suggests.  \n",
      "-> 적당한 육체 활동이 심장 질환을 예방하는 데 좋지만 활동의 정도를 높이는 더욱 더욱 좋을 수 특히 특히 운동을 운동을 함께 것이 이상의 이상의 \n",
      "\n",
      "High-intensity exercise includes running or jogging at 6 mph, while low-intensity activities include walking at a pace of about 2 mph.  \n",
      "-> 강도가 높은 운동에는 달리기나 시간당 6마일의 속도로 조깅하는 것이 포함되는 반면에, 강도가 낮은 운동에는 약 약 2마일의 걷는 걷는 포함된다. \n",
      "\n",
      "Researchers also have debated whether weight-training has a big impact on the heart, since it does not give the heart and lungs the kind of workout they get from aerobic activities such as brisk walking or running for at least 20 minutes.  \n",
      "-> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 활동에서 얻는 효과를 심장과 폐에 주지 않기 않기 때문에, 때문에, 운동이 심장에 심장에 미치는지 여부에 논쟁을 논쟁을 \n",
      "\n",
      "But in the Harvard School of Public Health study, men who engaged in weight training for 30 minutes or more weekly had a 23 percent lower risk of heart disease than men who did not pump iron.  \n",
      "-> 그러나 이번 하버드 공중 위생 학교의 연구에서는, 일주일에 30분이나 그 이상 이상 운동을 한 남성들이 아령으로 않는 남성들보다 심장병에 걸릴 걸릴 위험이 23% 23% 있다.\" 고 \n",
      "\n",
      "The researchers said the benefits may result in part from reductions in blood pressure and body fat achieved through weight training.  \n",
      "-> 이러한 긍정적인 효과는 부분적으로는 근력 운동을 통해 얻어진 혈압과 신체 지방의 감소에 감소에 것일 수 수 연구학자들은 연구학자들은 \n",
      "\n",
      "Given the independent results from weight training, the researchers theorized that adding weight training to a high-intensity exercise program would reap even greater benefits.  \n",
      "-> 근력 운동에 의한 독립적인 결과를 고려하면, 근력 운동을 강도 높은 운동 프로그램에 추가하는 훨씬 훨씬 큰 효과를 얻을 얻을 있을 있을 연구학자들은 이론화하였다. \n",
      "\n",
      "The study is based on medical records and questionnaires given periodically to 44,452 health professionals from 1986 to 1998.  \n",
      "-> 이번 연구 조사는 1986년에서 1998년 사이 의 의학 보고서와 44,452명의 건강 전문가들에게 정기적으로 보낸 설문서에 근거한 \n",
      "\n",
      "Participants were ages 40 to 75 at the outset.  \n",
      "-> 연구가 시작될 때에 참가자들의 나이는 40세에서 75세 사이였다. \n",
      "\n",
      "Heart disease was ultimately diagnosed in 1,700 participants.  \n",
      "-> 결과적으로 1,700명의 참가자들에게서 심장 질환이 진단되었다. \n",
      "\n",
      "Men who ran for an hour or more weekly at 6 mph or more were 42 percent less likely to develop heart disease than non-runners.  \n",
      "-> 일주일에 한 시간 또는 그 이상 동안 시속 6마일 이상의 속도로 달린 사람들은 달리기를 않은 않은 사람들보다 질환에 질환에 가능성이 42%나 낮았다. \n",
      "\n",
      "Men who did brisk walking at a moderate pace of at least 3 mph for at least a half hour daily were 18 percent less likely to develop heart disease than those who did not.  \n",
      "-> 매일 최소한 30분 동안 적어도 시간당 3마일의 적당한 속도로 활발하게 걸었던 사람들은 그렇게 하지 않은 사람들보다 사람들보다 질환에 걸릴 걸릴 18% 낮았다. 낮았다. \n",
      "\n",
      "There were no significant heart benefits found from low-intensity walking.  \n",
      "-> 강도가 약하게 걷는 것으로부터 발견된 현저한 심장 (질환 억제) 효과는 \n",
      "\n",
      "Gerald Fletcher, an American Heart Association spokesman.  \n",
      "-> 라고 미국 심장 협회 대변인인 제럴드 플레처 박사가 \n",
      "\n",
      "He said the findings correspond with AHA guidelines, which recommend aerobic exercise at least six days a week and weight-training two or three times weekly.  \n",
      "-> 그는 이 연구 결과가 美 심장 협회의 지침과도 부합된다고 말했는데, 美 심장 협회의 지침은 지침은 적어도 6일은 6일은 하고, 매주 매주 23번은 근력 \n",
      "\n",
      "But Fletcher said, \"A little is better than sitting in front of the television.\"  \n",
      "-> 그러나 \"(운동을) 조금이라도 하는 것이 텔레비전 앞에 앉아 있는 것보다는 좋습니다.\" 플레처 박사는 말했다. \n",
      "\n",
      "Days before the premiere of \"Harry Potter and the Chamber of Secrets,\" the film's producer said it fears pirated copies are showing up on the Internet.  \n",
      "-> \"해리포터와 비밀의 방\"의 개봉을 며칠 앞두고, 이 영화의 제작사는 해적판이 인터넷에 출현하고 있어 걱정이 된다고 \n",
      "\n",
      "an illegal copy of the film has appeared on the Internet, which often contains bootleg copies of films, even before they hit theaters.  \n",
      "-> 워너 브러더스는 이 영화의 불법 복제판이 인터넷 상에 나타났다고 밝혔는데, 인터넷에는 영화가 극장에서 상영되기도 불법 불법 복제판이 나타나는 종종 \n",
      "\n",
      "The studio later retracted the statement, saying reports of bootleg copies hadn't been substantiated, but an AP search discovered what appeared to be the movie available on a site hosted in Europe.  \n",
      "-> 핵무기 개발 완료를 공식 발표한 북한 \n",
      "\n",
      "it has developed a nuclear weapon.  \n",
      "-> 북한이 핵무기를 개발했다고 처음으로 밝혔다. \n",
      "\n",
      "the country \"has come to have nuclear and other strong military weapons to deal with increased nuclear threats by the U.S. imperialists,\" according to the Yonhap news agency which monitors North Korean broadcasts.  \n",
      "-> 북한 방송을 감시 청취하는 연합 통신에따르면, 북한은 \"미국 제국주의자들에 제국주의자들에 증가한 핵 위협에 대처하기 대처하기 핵무기와 핵무기와 강력한 무기들을 무기들을 보유하게 되었다.\" \n",
      "\n",
      "It was unclear, however, whether the report referred to a plutonium- or uranium-based weapon.  \n",
      "-> 그러나 그 보도가 언급한 것이 플루토늄에 의한 무기인지 우라늄에 무기인지는 무기인지는 명확하지 않았다. \n",
      "\n",
      "despite the high-tech industry's downturn, co-founder Bill Gates said as he unveiled a strategy to push \"smart\" computing technology into everyday gadgets such as alarm clocks and pens.  \n",
      "-> 마이크로소프트社의 공동 창업자인 빌 게이츠는 알람 시계와 펜과 같은 일상 생활용품에 지능형 컴퓨터 기술을 결합시키는 전략을 발표하면서, 첨단 침체에도 불구하고 불구하고 혁신은 계속 되고 \n",
      "\n",
      "Gates, who opened the 23rd annual Comdex trade show, said there was a negative perception of high tech following the collapse of the tech bubble about two years ago.  \n",
      "-> 제 23차 연례 컴덱스 박람회의 개회사를 한 케이츠는 2년여전 기술 산업의 거품이 붕괴된 이후에 첨단 첨단 기술에 부정적인 인식이 인식이 무기도 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, seq in enumerate(english):\n",
    "    temp = ''\n",
    "    for token in seq:\n",
    "        temp += token + ' '\n",
    "    #print(temp)\n",
    "    print(temp, '\\n->', translate(seq), '\\n')\n",
    "    if i == 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensor",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
